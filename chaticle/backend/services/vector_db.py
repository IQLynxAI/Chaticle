import faiss
import numpy as np
import os
import json
from sentence_transformers import SentenceTransformer
from config import FAISS_DB_PATH, EMBEDDING_MODEL


class VectorDatabase:
    """
    A class to handle vector-based document storage and retrieval using FAISS.
    """
    def __init__(self):
        """
        Initializes the VectorDatabase by loading or creating a FAISS index.
        """
        self.model = SentenceTransformer(EMBEDDING_MODEL)
        self.index = None
        self.documents = []
        self.chat_history = []
        self.load_or_create_index()

    def load_or_create_index(self):
        """
        Loads an existing FAISS index or creates a new one if it doesn't exist.
        """
        os.makedirs(os.path.dirname(FAISS_DB_PATH), exist_ok=True)

        if os.path.exists(FAISS_DB_PATH):
            print("üîπ Loading FAISS index...")
            self.index = faiss.read_index(FAISS_DB_PATH)
            with open(FAISS_DB_PATH + ".json", "r") as f:
                self.documents = json.load(f)
        else:
            print("üîπ Creating new FAISS index...")
            self.index = faiss.IndexFlatL2(384)
            self.documents = []

    def store_document(self, content: str):
        """
        Stores a document in the vector database and resets the FAISS index.

        Args:
            content (str): The content to be stored in the vector database.
        """
        print("‚ö†Ô∏è Resetting FAISS index before storing new content...")

        self.index = faiss.IndexFlatL2(384)
        self.documents = []
        self.chat_history = []

        embedding = self.model.encode([content])[0]
        self.index.add(np.array([embedding], dtype=np.float32))
        self.documents.append(content)

        os.makedirs(os.path.dirname(FAISS_DB_PATH), exist_ok=True)
        faiss.write_index(self.index, FAISS_DB_PATH)
        with open(FAISS_DB_PATH + ".json", "w") as f:
            json.dump(self.documents, f)

    def store_chat(self, user_message: str, bot_response: str):
        """
        Stores a conversation in the chat history.

        Args:
            user_message (str): The message sent by the user.
            bot_response (str): The response generated by the bot.
        """
        self.chat_history.append({"user": user_message, "bot": bot_response})

    def get_chat_history(self):
        """
        Retrieves the last 5 messages from the chat history for context.

        Returns:
            list: A list of the last 5 chat messages.
        """
        return self.chat_history[-5:]

    def search(self, query: str, top_k=3):
        """
        Searches the vector database for relevant content based on the query.

        Args:
            query (str): The query to search for.
            top_k (int): The number of top results to retrieve.

        Returns:
            list: A list of relevant content or a default message if no content is found.
        """
        if len(self.documents) == 0:
            return ["No relevant information found. Try opening the extension on a webpage first."]

        query_embedding = self.model.encode([query])[0]
        distances, indices = self.index.search(np.array([query_embedding], dtype=np.float32), top_k)
        results = [self.documents[idx] for idx in indices[0] if idx < len(self.documents)]
        return results


vector_db = VectorDatabase()